{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBdiD49e5Q7L"
      },
      "source": [
        "# **Lab 4: Adversarial Attacks Against Machine Learning Based Spam Filters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPJYb7EA5a24"
      },
      "source": [
        "Please Type the Names of the Team Members:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSubQvScyKdQ"
      },
      "source": [
        "## **Introduction**\n",
        "Machine learning-based spam detection models learn from a set of labeled training data and detect spam emails. One class of vulnerabilities can help an attack to slightly modify the spam emails, called adversarial examples, to manipulate a trained model, e.g., a support vector machine(SVM) classifier, to misclassify maliciously during detection. However, feature extraction methods can make it difficult to translate numerical changes in the feature space, to needed changes to an email consisting of words.\n",
        "\n",
        "This lab uses a new attack method to understand how adversarial examples purposely modify the TF-IDF (term frequency-inverse document frequency) feature vector representing an email. A set of \"magic words\", or \"malicious words\" are identified from the TF-IDF vectors that experience the most significant changes made by a Projected Gradient Descent (PGD) algorithm. Adding these magic words to a spam email increases the chance for desirable misclassifications.\n",
        "\n",
        "## **Publications**\n",
        "\n",
        "For more information on this method, you can refer to the following publications:\n",
        "\n",
        "(1) C. Wang, D. Zhang, S. Huang, X. Li, and L. Ding, “Crafting Adversarial Email Content against Machine Learning Based Spam Email Detection,” In Proceedings of the 2021 International Symposium on Advanced Security on Software and Systems (ASSS ’21) with AsiaCCS 2021, Virtual Event, Hong Kong, June 7, 2021. [Download](https://isi.jhu.edu/wp-content/uploads/2021/04/ASSS_Workshop_Paper.pdf)\n",
        "\n",
        "(2) Q. Cheng, A. Xu, X. Li, and L. Ding, “Adversarial Email Generation against Spam Detection Models through Feature Perturbation,” The 2022 IEEE International Conference on Assured Autonomy (ICAA’22), Virtual Event, March 22-23, 2022. [Download](https://isi.jhu.edu/wp-content/uploads/2022/04/Adversarial_Attacks_Against_Machine_Learning_Based_SpamFilters__IEEE.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv-y6Ac6FYWO"
      },
      "source": [
        "## **1. Loading Dataset**\n",
        "The dataset to be used is called Ling-Spam. The Ling-Spam dataset is a collection of 2,893 spam and ham email messages curated from the Linguist List. These messages focus on linguistic interests around job postings, research opportunities, and software discussion. You can download this dataset below coming with the lab assignment.\n",
        "\n",
        "### Acknowledgements\n",
        "The dataset and its information come from the original authors of \"A Memory-Based Approach to Anti-Spam Filtering for Mailing Lists\". \\\\\n",
        "\n",
        "**Run the code block below:**\n",
        "\n",
        "choose the message.csv to upload. Wait until it shows 100% before you continue. The below code is for the \"Google Colab\" environment, for another environment (like Jupyter Notebook), you can choose the corresponding upload function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "TXkAvUlp4fRP",
        "outputId": "36f9c9c6-1053-43a4-ba3e-b95e2b2e0755"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be0890a6-4a41-4241-8dcb-f4cf323b8a76\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be0890a6-4a41-4241-8dcb-f4cf323b8a76\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving messages.csv to messages (3).csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1re2gZWrle_P"
      },
      "source": [
        "**Run the code block below:**\n",
        "\n",
        "This splits the loaded dataset into three subsets of training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CZvxGJk-rkkc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def data_extraction():\n",
        "\n",
        "  # Change the 'messages.csv' to the filename you uploaded.\n",
        "  df = pd.read_csv('messages.csv')\n",
        "  x = df.message\n",
        "  y = df.label\n",
        "  # We first separate the entire dataset to 80% and 20%.\n",
        "  # Let the 80% of entire dataset becoming the first dataset(which will be split to traning dataset and the validation dataset), and let the 20% of entire dataset becoming the testing dataset.\n",
        "  x_train_val, x_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=99, stratify=y)\n",
        "  # Let the 80% of the train_val dataset be the traning dataset, and the 20% of the train_val dataset be the validation dataset.\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.2, random_state=99, stratify=y_train_val)\n",
        "\n",
        "\n",
        "  return x_train, x_val, x_test, y_train, y_val, y_test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2aXVdK7DLuy",
        "outputId": "68f62c08-e395-4e85-d159-98812b1ef571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2304    content length student net looking reference f...\n",
            "1412    anthropological linguistics volume number wint...\n",
            "2124    pre final programme participation workshop lan...\n",
            "416     putting syllabus undergraduate sociolinguistic...\n",
            "2058    twendial th twente workshop language technolog...\n",
            "                              ...                        \n",
            "2294    h stephen straight right mention importance es...\n",
            "1059    hi wondering interested subscribing optin emai...\n",
            "36      interested making day month willing forth hone...\n",
            "1660    kyushu institute technology national universit...\n",
            "446     international conference linguistics marking a...\n",
            "Name: message, Length: 1480, dtype: object\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, X_test, Y_train, Y_val, Y_test = data_extraction()\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFUv7AmsFW8e"
      },
      "source": [
        "In the code block above, we have read the dataset into variables x\n",
        "and y. Variable x contains the email body in a list of words and variable y contains the class labels with 0 being ham and 1 being spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w-WXw69wAT6"
      },
      "source": [
        "We divide the entire data set randomly into three different data sets which are training data, validation data, and testing data. After we split the dataset twice: 64% of the entire dataset becomes the traning dataset(Y_train), 16% becomes the validation dataset(X_val), and 20% becomes the testing dataset(X_test).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCGLR9neo8zL"
      },
      "source": [
        "### **Question 1**\n",
        "\n",
        "Why do we need the three data subsets described above? Please explain what is a training dataset, a validation dataset, and a testing dataset. For some additional insights, you can refer to the article at https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7. (However, note that the validation dataset is also used to identify the magical words in this lab, kind of different from its typical use.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJ7iGauJih3"
      },
      "source": [
        "## **2. Preprocessing the Emails**\n",
        "For preparation for use, we remove all the HTML tags, numbers, punctuation marks, and English stop words to keep only useful information. We also convert all the words to lowercase and each paragraph into a single line instead of multiple lines. In the last step of preprocessing, we conduct stemming on all the words.\n",
        "\n",
        "\\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfS6VpTaH7Wu",
        "outputId": "a544b40f-a2e5-437d-f228-5bf426fe307c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Remove the hyperlink.\n",
        "def remove_hyperlink(word):\n",
        "\n",
        "    return re.sub(r\"http\\S+\", \" \", word)\n",
        "\n",
        "\n",
        "# Convert the letter to lowercase.\n",
        "def to_lower(word):\n",
        "    result = word.lower()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the numbers.\n",
        "def remove_number(word):\n",
        "    result = re.sub(r'\\d+', ' ', word)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the puncturations.\n",
        "def remove_punctuation(word):\n",
        "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Remove the whitespace.\n",
        "def remove_whitespace(word):\n",
        "    result = word.strip()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Merge multiple lines into one line.\n",
        "def replace_newline(word):\n",
        "\n",
        "    return word.replace('\\n', ' ')\n",
        "\n",
        "\n",
        "def clean_up_pipeline(sentence):\n",
        "    # Ensure the input is a string\n",
        "    if not isinstance(sentence, str):\n",
        "        sentence = str(sentence)\n",
        "\n",
        "    cleaning_utils = [remove_hyperlink, replace_newline, to_lower, remove_number, remove_punctuation, remove_whitespace]\n",
        "    for o in cleaning_utils:\n",
        "        sentence = o(sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "# Remove the stopwords, for example: a, and, an, above, ..., etc.\n",
        "def remove_stop_words(words):\n",
        "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Reduce a word to its root word.\n",
        "def word_stemmer(words):\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    return [stemmer.stem(o) for o in words]\n",
        "\n",
        "\n",
        "# Remove inflectional endings only and to return the base.\n",
        "def word_lemmatizer(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    return [lemmatizer.lemmatize(o) for o in words]\n",
        "\n",
        "\n",
        "# Clear out the unnecessary information.\n",
        "def clean_token_pipeline(words):\n",
        "    cleaning_utils = [remove_stop_words, word_lemmatizer]\n",
        "\n",
        "    for o in cleaning_utils:\n",
        "        words = o(words)\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "def preprocess(X_train, X_val, X_test):\n",
        "    # Ensure all elements are strings\n",
        "    X_train = [str(x) if not isinstance(x, str) else x for x in X_train]\n",
        "    X_test = [str(x) if not isinstance(x, str) else x for x in X_test]\n",
        "    X_val = [str(x) if not isinstance(x, str) else x for x in X_val]\n",
        "\n",
        "    x_train_clean = [clean_up_pipeline(o) for o in X_train]\n",
        "    x_test_clean = [clean_up_pipeline(o) for o in X_test]\n",
        "    x_val_clean = [clean_up_pipeline(o) for o in X_val]\n",
        "    x_train_tokenize = [word_tokenize(o) for o in x_train_clean]\n",
        "    x_test_tokenize = [word_tokenize(o) for o in x_test_clean]\n",
        "    x_val_tokenize = [word_tokenize(o) for o in x_val_clean]\n",
        "    x_train_clean_token = [clean_token_pipeline(o) for o in x_train_tokenize]\n",
        "    x_test_clean_token = [clean_token_pipeline(o) for o in x_test_tokenize]\n",
        "    x_val_clean_token = [clean_token_pipeline(o) for o in x_val_tokenize]\n",
        "    x_train = [\" \".join(o) for o in x_train_clean_token]\n",
        "    x_test = [\" \".join(o) for o in x_test_clean_token]\n",
        "    x_val = [\" \".join(o) for o in x_val_clean_token]\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoPue9h3Ik--",
        "outputId": "bb80c2ce-579a-4bd8-c484-5ae9081a54bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content length student net looking reference formal systematized description discourse dialog tour parole levison s work word use automatic analyzer political discourse topic local water syntax parsing d appreciate help provide answer directly walther uni unige ch ll post summary thanks catherine walther u geneva\n"
          ]
        }
      ],
      "source": [
        "x_train, x_val, x_test = preprocess(X_train, X_val, X_test)\n",
        "print(x_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N68YIZqIJmc8"
      },
      "source": [
        "## **3. Feature Extraction**\n",
        "In this step, we convert the words of an email into a numerical feature vector, representing information of that email used for classification. Among many such methods, this lab will use TF-IDF. TF-IDF stands for term frequency-inverse document frequency. It is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in information retrieval and text mining. The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\\\\\n",
        "\n",
        "\\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wlpwcsgxJrMK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "def convert_to_feature(raw_tokenize_data):\n",
        "    raw_sentences = [' '.join(o) for o in raw_tokenize_data]\n",
        "\n",
        "    return vectorizer.transform(raw_sentences)\n",
        "\n",
        "\n",
        "def TfidfConvert(x_train, x_test, x_val):\n",
        "    x_train = [o.split(\" \") for o in x_train]\n",
        "    x_test = [o.split(\" \") for o in x_test]\n",
        "    x_val = [o.split(\" \") for o in x_val]\n",
        "    x_train_raw_sentences = [' '.join(o) for o in x_train]\n",
        "    x_val_raw_sentences = [' '.join(o) for o in x_val]\n",
        "    raw_sentences = x_train_raw_sentences + x_val_raw_sentences\n",
        "    vectorizer.fit(raw_sentences)\n",
        "    x_train_features = convert_to_feature(x_train)\n",
        "    x_test_features = convert_to_feature(x_test)\n",
        "    x_val_features = convert_to_feature(x_val)\n",
        "\n",
        "\n",
        "    return x_train_features, x_test_features, x_val_features\n",
        "\n",
        "\n",
        "def feature_extraction(x_train, x_test, x_val):\n",
        "    x_train_features, x_test_features, x_val_features = TfidfConvert(x_train, x_test, x_val)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "    return x_train_features, x_test_features, x_val_features, feature_names, vectorizer, 'NaN'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKUZs88oPQHI",
        "outputId": "adb4bdd5-5206-44b9-ac13-9faf3861988e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 41993)\t0.07512236669900772\n",
            "  (0, 41960)\t0.07420235254046403\n",
            "  (0, 41289)\t0.17991300005024335\n",
            "  (0, 41206)\t0.4416403353969477\n",
            "  (0, 40072)\t0.07812616027660503\n",
            "  (0, 39648)\t0.202048950334105\n",
            "  (0, 39606)\t0.19564044624902785\n",
            "  (0, 38439)\t0.16153850115029383\n",
            "  (0, 38358)\t0.08616245901279183\n",
            "  (0, 37792)\t0.10145609731304224\n",
            "  (0, 37059)\t0.25008230228574047\n",
            "  (0, 37025)\t0.09136919891479676\n",
            "  (0, 36634)\t0.11034063903972836\n",
            "  (0, 36292)\t0.08922507669748314\n",
            "  (0, 31432)\t0.08371514431705784\n",
            "  (0, 30368)\t0.09759342420984102\n",
            "  (0, 29460)\t0.11486430860274591\n",
            "  (0, 29279)\t0.14093574571866804\n",
            "  (0, 28054)\t0.14041645906252576\n",
            "  (0, 28043)\t0.1857355165807253\n",
            "  (0, 25837)\t0.12124711013054038\n",
            "  (0, 22395)\t0.10974369781474626\n",
            "  (0, 22260)\t0.11604287133874543\n",
            "  (0, 22204)\t0.1099414410205347\n",
            "  (0, 21695)\t0.22082016769847385\n",
            "  (0, 21565)\t0.11350514919865842\n",
            "  (0, 16306)\t0.10026211056046669\n",
            "  (0, 14560)\t0.16580288301805737\n",
            "  (0, 13616)\t0.11328414191038517\n",
            "  (0, 9830)\t0.20539292784821994\n",
            "  (0, 9746)\t0.11306465358454652\n",
            "  (0, 9497)\t0.19030550294040385\n",
            "  (0, 9257)\t0.10482083023253505\n",
            "  (0, 7539)\t0.09679499698085937\n",
            "  (0, 5808)\t0.1646822267815134\n",
            "  (0, 5541)\t0.17072575060026862\n",
            "  (0, 2759)\t0.14041645906252576\n",
            "  (0, 1956)\t0.1544123168468889\n",
            "  (0, 1696)\t0.11463372691005383\n",
            "  (0, 1439)\t0.22082016769847385\n"
          ]
        }
      ],
      "source": [
        "x_train_features, x_test_features, x_val_features, feature_names, feature_model, scalar = feature_extraction(x_train, x_test, x_val)\n",
        "print(x_train_features[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MND-TjQRXkpq"
      },
      "source": [
        "### **Question 2**\n",
        "Please research TF-IDF online and provide a concise explanation of how it is done in your own words in one paragraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAbh0HSVrCQd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0RZeCBFLSH9"
      },
      "source": [
        "## **4. Training SVM**\n",
        "In this step, we will train a Support Vector Machine (SVM) model as a spam filter. Then we use the validation dataset to evaluate how it performs.\n",
        "\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAeBdHNfLM7k",
        "outputId": "99c2f58a-467c-4f35-ba46-c54d1110d2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: secml in /usr/local/lib/python3.10/dist-packages (0.15.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from secml) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from secml) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from secml) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from secml) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from secml) (1.4.2)\n",
            "Requirement already satisfied: Pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from secml) (9.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from secml) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from secml) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->secml) (3.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->secml) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->secml) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->secml) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install secml\n",
        "from secml.data import CDataset\n",
        "from secml.data.splitter import CDataSplitterKFold\n",
        "from secml.ml.classifiers import CClassifierSVM\n",
        "from secml.ml.peval.metrics import CMetricAccuracy\n",
        "from secml.ml.peval.metrics import CMetricConfusionMatrix\n",
        "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
        "# from Feature_extraction import single_transform\n",
        "import csv\n",
        "from statistics import mean, stdev\n",
        "import threading\n",
        "import time\n",
        "\n",
        "\n",
        "# We use the training data and validation data set to train the SVM model.\n",
        "def train_SVM(x_train_features, x_val_features, y_train, y_val):\n",
        "    tr_set = CDataset(x_train_features, y_train)\n",
        "    # Train the SVM\n",
        "    print(\"Build SVM\")\n",
        "    xval_splitter = CDataSplitterKFold()\n",
        "    clf_lin = CClassifierSVM()\n",
        "    xval_lin_params = {'C': [1]}\n",
        "    print(\"Find the best params\")\n",
        "    best_lin_params = clf_lin.estimate_parameters(\n",
        "        dataset=tr_set,\n",
        "        parameters=xval_lin_params,\n",
        "        splitter=xval_splitter,\n",
        "        metric='accuracy',\n",
        "        perf_evaluator='xval'\n",
        "    )\n",
        "    print(\"Finish Train\")\n",
        "    print(\"The best training parameters are: \", [\n",
        "          (k, best_lin_params[k]) for k in sorted(best_lin_params)])\n",
        "    print(\"Train SVM\")\n",
        "    clf_lin.fit(tr_set.X, tr_set.Y)\n",
        "\n",
        "    # Test the Classifier\n",
        "    v_set = CDataset(x_val_features, y_val)\n",
        "    y_pred = clf_lin.predict(v_set.X)\n",
        "    metric = CMetricAccuracy()\n",
        "    acc = metric.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    confusion_matrix = CMetricConfusionMatrix()\n",
        "    cm = confusion_matrix.performance_score(y_true=v_set.Y, y_pred=y_pred)\n",
        "    print(\"Confusion Matrix: \")\n",
        "    print(cm)\n",
        "\n",
        "\n",
        "    return tr_set, v_set, clf_lin\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi5HMdEVQ3a4",
        "outputId": "d06bcbce-c0ba-496e-9572-2e9fba05044e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build SVM\n",
            "Find the best params\n",
            "Finish Train\n",
            "The best training parameters are:  [('C', 1)]\n",
            "Train SVM\n",
            "Confusion Matrix: \n",
            "CArray([[309   0]\n",
            " [  3  59]])\n"
          ]
        }
      ],
      "source": [
        "tr_set, v_set, clf_lin = train_SVM(x_train_features, x_val_features, Y_train, Y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL1ZOAYQN12a"
      },
      "source": [
        "### **Question 3**\n",
        "Based on the confusion matrix provided above, calculate the following metrics: `accuracy`, `false-positive rate`, `false-negative rate`, `true-positive rate`, and `true-negative rate`. Please outline the steps you took to calculate each metric and include your results in the text block below. Additionally, provide an explanation of each metric in the context of spam email detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-UG3wUYOaLG"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rKjzZTCO5N2"
      },
      "source": [
        "## **5. PGD Attack**\n",
        "Adversarial perturbations are made to input features, i.e., the TF-IDF values corresponding to words. We employ the Projected Gradient Descent (PGD) method to modify the feature values for desirable adversarial examples in the feature domain. PGD algorithm iteratively finds the needed changes with a constraint parameter, *dmax*, which is the Euclidean distance to the original input indicating the allowed extent of perturbation, to achieve the maximum loss in classification. In our approach, we run PGD over a set of randomly selected spam emails form the validation sataset to generate adversarial examples in the feature space. Then we test these modified TF-IDF vectors to see whether they could successfully bypass the detection. \\\\\n",
        "\n",
        "\\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix7GUWE6yAxQ"
      },
      "source": [
        "**Note:**\n",
        "These are explanations for the terms used in the code:\n",
        "\n",
        "1. `clf_lin` - SVM Classifier:\n",
        "   - Represents a Support Vector Machine (SVM) classifier for email classification.\n",
        "\n",
        "2. `tr_set` - Training Set:\n",
        "   - A dataset used for training the SVM classifier, containing input features and labels.\n",
        "\n",
        "3. `v_set` - Validation Set:\n",
        "   - A dataset used to identify the \"best\" magic words through PGD.\n",
        "\n",
        "4. `Y_val` - Validation Set Labels:\n",
        "   - Contains labels for the validation set, aiding in performance evaluation.\n",
        "\n",
        "5. `feature_names` - Name of the Features:\n",
        "   - Likely holds the names or labels of the dataset's features.\n",
        "\n",
        "6. `nb_attack` - Number of Attacks:\n",
        "   - Determines how many adversarial examples should be generated (the number of spam emails to modify by PGD).\n",
        "\n",
        "7. `dmax` - Maximum Perturbation Distance:\n",
        "   - Represents the maximum allowed change in feature values during adversarial attacks, measured as Euclidean distance.\n",
        "\n",
        "8. `lb` - Lower Bound:\n",
        "   - Sets a lower boundary on feature values, constraining perturbations during attacks.\n",
        "\n",
        "9. `ub` - Upper Bound:\n",
        "   - Defines an upper boundary on feature values, limiting perturbations during attacks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lCvPfWA-P1OG"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(clf_lin, tr_set, v_set, y_val, feature_names, nb_attack, dmax, lb, ub):\n",
        "\n",
        "    class_to_attack = 1\n",
        "    cnt = 0  # the number of success adversaril examples\n",
        "    ori_examples2_x = []\n",
        "    ori_examples2_y = []\n",
        "\n",
        "    for i in range(nb_attack):\n",
        "        # take a point at random being the starting point of the attack\n",
        "        idx_candidates = np.where(y_val == class_to_attack)\n",
        "        # select nb_init_pts points randomly in candidates and make them move\n",
        "        rn = np.random.choice(idx_candidates[0].size, 1)\n",
        "        x0, y0 = v_set[idx_candidates[0][rn[0]], :].X, v_set[idx_candidates[0][rn[0]], :].Y\n",
        "\n",
        "        x0 = x0.astype(float)\n",
        "        y0 = y0.astype(int)\n",
        "        x2 = x0.tondarray()[0]\n",
        "        y2 = y0.tondarray()[0]\n",
        "\n",
        "        ori_examples2_x.append(x2)\n",
        "        ori_examples2_y.append(y2)\n",
        "\n",
        "\n",
        "    # Perform adversarial attacks\n",
        "\n",
        "    noise_type = 'l2'  # Type of perturbation 'l1' or 'l2'\n",
        "\n",
        "    y_target = 0\n",
        "\n",
        "    # dmax = 0.09  # Maximum perturbation\n",
        "\n",
        "    # Bounds of the attack space. Can be set to `None` for unbounded\n",
        "    solver_params = {\n",
        "        'eta': 0.01,\n",
        "        'max_iter': 1000,\n",
        "        'eps': 1e-4}\n",
        "\n",
        "    # set lower bound and upper bound respectively to 0 and 1 since all features are Boolean\n",
        "    pgd_attack = CAttackEvasionPGD(\n",
        "        classifier=clf_lin,\n",
        "        double_init_ds=tr_set,\n",
        "        distance=noise_type,\n",
        "        dmax=dmax,\n",
        "        lb=lb, ub=ub,\n",
        "        solver_params=solver_params,\n",
        "        y_target=y_target\n",
        "    )\n",
        "\n",
        "    ad_examples_x = []\n",
        "    ad_examples_y = []\n",
        "    ad_index = []\n",
        "    cnt = 0\n",
        "\n",
        "    for i in range(len(ori_examples2_x)):\n",
        "        x0 = ori_examples2_x[i]\n",
        "        y0 = ori_examples2_y[i]\n",
        "        y_pred_pgd, _, adv_ds_pgd, _ = pgd_attack.run(x0, y0)\n",
        "\n",
        "        if y_pred_pgd.item() == 0:\n",
        "            cnt = cnt + 1\n",
        "            ad_index.append(i)\n",
        "\n",
        "        ad_examples_x.append(adv_ds_pgd.X.tondarray()[0])\n",
        "        ad_examples_y.append(y_pred_pgd.item())\n",
        "\n",
        "        attack_pt = adv_ds_pgd.X.tondarray()[0]\n",
        "\n",
        "    print(\"PGD attack successful rate:\", cnt / nb_attack)\n",
        "\n",
        "    startTime2 = time.time()\n",
        "    ori_examples2_x = np.array(ori_examples2_x)\n",
        "    ori_examples2_y = np.array(ori_examples2_y)\n",
        "    ad_examples_x = np.array(ad_examples_x)\n",
        "    ad_examples_y = np.array(ad_examples_y)\n",
        "\n",
        "    ori_dataframe = pd.DataFrame(ori_examples2_x, columns=feature_names)\n",
        "    ad_dataframe = pd.DataFrame(ad_examples_x, columns=feature_names)\n",
        "\n",
        "    # extract the success and fail examples\n",
        "\n",
        "    ad_dataframe['ad_label'] = ad_examples_y\n",
        "    ad_success = ad_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ori_success = ori_dataframe.loc[ad_dataframe.ad_label == 0]\n",
        "    ad_fail = ad_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "    ori_fail = ori_dataframe.loc[ad_dataframe.ad_label == 1]\n",
        "\n",
        "    ad_success_x = ad_success.drop(columns=['ad_label'])\n",
        "    ad_fail_x = ad_fail.drop(columns=['ad_label'])\n",
        "\n",
        "    result = (ad_success_x - ori_success)\n",
        "    ori_dataframe.to_csv('ori_dataframe.csv')\n",
        "    ad_dataframe.to_csv('ad_dataframe.csv')\n",
        "    result.to_csv('result.csv')\n",
        "\n",
        "\n",
        "\n",
        "    return result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, cnt/nb_attack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qmM8uxrzrg"
      },
      "source": [
        "**Then run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RYKIvm0QMHD",
        "outputId": "bb09e509-cb76-41ff-dea4-a0fb795bb246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PGD attack successful rate: 0.13\n"
          ]
        }
      ],
      "source": [
        "lb = np.ndarray.min(x_train_features.toarray())\n",
        "ub = np.ndarray.max(x_train_features.toarray())\n",
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf2zyWXxnsxx"
      },
      "source": [
        "### **Question 4**\n",
        "Please explain, in your own words, how the success rate is calculated based on the code above. Then, compare this success rate to the original false negative rate of the classifier on the validation set. What do you observe from this comparison?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGPj3veloy7h"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUx6FBQiCBr"
      },
      "source": [
        "## **6. Identifying Magical Words**\n",
        "Adversarial emails are crafted by adding “magic words” to the original spam emails. The “magic words” are identified by intersecting the unique ham words with the “top words”. Specifically,  the unique ham words only appear in ham emails but not in spam emails.  After the  PGD  attacks on the set of randomly selected spam emails, we examine statistically which features are modified to the largest extent in the effort to bypass detection, to find their corresponding “top words”. (The changes are measured by calculating the variance of TF-IDF differences ver these spam emails before and after the PGD perturbation.) In  our  experiments,  we  use  the  top 100  words,  which  is relatively efficient. This set is relatively small and effective. \\\\\n",
        "\n",
        "\\\\\n",
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Mc552xOTSQZn"
      },
      "outputs": [],
      "source": [
        "def magical_word(x_train, x_val, y_train, y_val, x_test, y_test, result, cnt):\n",
        "\n",
        "    # Method 2: calculate feature importance\n",
        "    result_array = np.array(result)\n",
        "    weighted_result = result.multiply(result_array)\n",
        "\n",
        "    average_importance = weighted_result.sum() / cnt\n",
        "    average_importance_df = pd.DataFrame(average_importance, columns=['importance'])\n",
        "    sorted_features = average_importance_df.sort_values(by='importance', ascending=False, inplace=False)\n",
        "\n",
        "    important_features_df = pd.DataFrame(sorted_features.index[:100])\n",
        "    important_features_df.to_csv(\"important_features.csv\")\n",
        "\n",
        "    # Combine train and validation datasets\n",
        "    train_data = pd.DataFrame({'message': x_train, 'label': y_train})\n",
        "    val_data = pd.DataFrame({'message': x_val, 'label': y_val})\n",
        "    combined_data = pd.concat([train_data, val_data])\n",
        "    combined_data.to_csv(\"combined_messages.csv\")\n",
        "\n",
        "    # Separate spam and ham messages\n",
        "    spam_messages = combined_data[combined_data.label == 1]\n",
        "    ham_messages = combined_data[combined_data.label == 0]\n",
        "\n",
        "    # Save test messages\n",
        "    test_data = pd.DataFrame({'message': x_test, 'label': y_test})\n",
        "    test_data.to_csv(\"test_messages.csv\")\n",
        "    spam_test_messages = test_data[test_data.label == 1]\n",
        "\n",
        "    # Tf-idf for spam datasets\n",
        "    tfidf_vectorizer_spam = TfidfVectorizer()\n",
        "    tfidf_vectorizer_spam.fit_transform(spam_messages['message'])\n",
        "    spam_feature_names = tfidf_vectorizer_spam.get_feature_names_out()\n",
        "\n",
        "    # Tf-idf for ham datasets\n",
        "    tfidf_vectorizer_ham = TfidfVectorizer()\n",
        "    tfidf_vectorizer_ham.fit_transform(ham_messages['message'])\n",
        "    ham_feature_names = tfidf_vectorizer_ham.get_feature_names_out()\n",
        "\n",
        "    # find unique ham words\n",
        "    unique_ham_words = list(set(ham_feature_names) - set(spam_feature_names))\n",
        "    unique_ham_words_df = pd.DataFrame(unique_ham_words)\n",
        "    unique_ham_words_df.to_csv(\"unique_ham_words.csv\")\n",
        "\n",
        "    with open(\"important_features.csv\", \"r\") as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        important_features = [row[1] for row in reader]\n",
        "\n",
        "    important_features = important_features[1:]\n",
        "    # in ham & top100\n",
        "\n",
        "    ham_words_in_important_features = list(set(unique_ham_words).intersection(set(important_features)))\n",
        "    ham_words_str = \" \".join(ham_words_in_important_features)\n",
        "\n",
        "    return ham_words_str, spam_messages, ham_messages, spam_test_messages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjldI2rTs_N5"
      },
      "source": [
        "**Run the code block below to list the magic words:**\n",
        "\n",
        "Variable identified_magic_words contains the identified magic words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yC_GNgts8UO",
        "outputId": "7b12ef86-21f6-4be9-cb53-df511ae0d3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "teaching vt marvelous workshop linguist risked ammondt latin spanish translation french alinguist benjamin ipa linguistic siouan colingacl tei teacher uga sentence euralex german chorus elra cascadilla nan\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "identified_magic_words, spam, ham, spam_test = magical_word(x_train, x_val, Y_train, Y_val, x_test, Y_test, result, cnt)\n",
        "print(identified_magic_words)\n",
        "print(len(identified_magic_words.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgS8EWh6qwSl"
      },
      "source": [
        "### **Question 5**\n",
        "(1). Based on your understanding after reading the paper using the link below, explain what is a \"good word\" attack?\n",
        "(Reference: https://www.ceas.cc/papers-2005/125.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl1YCa2XyuTM"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulr-4hJpysdz"
      },
      "source": [
        "(2). The use of the good words is similar to our \"magic words\" in this approach.\n",
        "What is the difference in finding \"magic words\" from finding \"good words\"?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owxAMmiYyu5B"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdpkxWJ-RiOz"
      },
      "source": [
        "### **Task 1**\n",
        "In the code block below, try to run pgd_attack with different dmax values.\n",
        "\n",
        "What will happen when you try a higher dmax? Show the relationship by plotting dmax values and the corresponding PGD attack successful rate in a graph. You can do this by changing the code below with different dmax values. Try at least 5 dmax and explain your findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "JgJtZ1gXSNUF",
        "outputId": "f0f8d464-4807-4fd3-b464-7ac1f06cd00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PGD attack successful rate: 0.14\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7bcaf75a6a10>]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)\n",
        "\n",
        "# this plot cotains a single dmax vs the successful rate,\n",
        "# you can either write a for loop to try 5 or more dmax, or just manually\n",
        "# modify dmax values and record the results.\n",
        "list_dmax = [dmax]\n",
        "list_successful_rate = [successful_rate]\n",
        "plt.plot(list_dmax, list_successful_rate, 'b-o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr71cHstiQGv"
      },
      "source": [
        "### **Task 2**\n",
        "How many magical words did you get in attacks? List the magical words in the following text block. Find the relationship between the number of magical words and dmax of PGD attack. Plot a graph to show this relationship. Try at least 5 different dmax values. Explain your findings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SglR24OotQvS"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "MUYgM6b2tVQw",
        "outputId": "c8b0ab46-2c9f-4b4c-d7ac-862af683db0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PGD attack successful rate: 0.15\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7bcaf7e36260>]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "attack_amount = 100\n",
        "dmax = 0.06\n",
        "result, cnt, ad_success_x, ori_dataframe, ori_examples2_y, successful_rate = pgd_attack(clf_lin, tr_set, v_set, Y_val, feature_names, attack_amount, dmax, lb, ub)\n",
        "identified_magic_words, spam, ham, spam_test = magical_word(x_train, x_val, Y_train, Y_val, x_test, Y_test, result, cnt)\n",
        "\n",
        "# this plot cotains a single dmax vs the number of magical words,\n",
        "# you can either write a for loop do to 5 or more dmax, or just manually\n",
        "# record dmax values\n",
        "list_dmax = [dmax]\n",
        "list_len = [len(identified_magic_words.split())]\n",
        "#print (identified_magic_words)\n",
        "#print(list_len)\n",
        "plt.plot(list_dmax, list_len, 'b-o')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9e3VAwouiQK"
      },
      "source": [
        "## **7. Crafting Adversarial Emails & Attacking SVM**\n",
        "After we find the magical words, we then add them to a spam email to evaluate how effectively the \"magic words\" can bypass the classifier. This is what we called \"crafting adversarial emails\". Then, we feed the new TF-IDF vectors of these crafted emails to the SVM classifier to see if they would be misclassified as ham emails.  \\\\\n",
        "\n",
        "\\\\\n",
        "**Run the code block below:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PxY8tJakw2yv"
      },
      "outputs": [],
      "source": [
        "m2_empty = pd.DataFrame()\n",
        "spam_cnt = 0\n",
        "threads = []\n",
        "m2_empty_l1 = pd.DataFrame()\n",
        "m2_empty_l2 = pd.DataFrame()\n",
        "m2_empty_l3 = pd.DataFrame()\n",
        "m2_empty_l4 = pd.DataFrame()\n",
        "m2_list = [m2_empty_l1, m2_empty_l2, m2_empty_l3, m2_empty_l4]\n",
        "\n",
        "\n",
        "def single_transform(x, method, feature_model, feature_names, scalar, selection_model):\n",
        "\n",
        "  result = feature_model.transform(x)\n",
        "\n",
        "  if selection_model != 'NaN':\n",
        "    result = selection_model.transform(result)\n",
        "\n",
        "\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "class myThread(threading.Thread):\n",
        "\n",
        "    def __init__(self, threadID, name, spam_message, identified_magic_words, method, feature_model, feature_names, scalar, clf_lin, list_index, selection_model):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.threadID = threadID\n",
        "        self.name = name\n",
        "        self.spam_message = spam_message\n",
        "        self.identified_magic_words = identified_magic_words\n",
        "        self.method = method\n",
        "        self.feature_model = feature_model\n",
        "        self.feature_names = feature_names\n",
        "        self.scalar = scalar\n",
        "        self.clf_lin = clf_lin\n",
        "        self.list_index = list_index\n",
        "        self.lock = threading.Lock()\n",
        "        self.selection_model = selection_model\n",
        "\n",
        "    def run(self):\n",
        "        global spam_cnt\n",
        "        print(\"Starting \" + self.name)\n",
        "        spam_cnt_1 = m2_empty_out(self.name, self.spam_message, self.identified_magic_words, self.method,\n",
        "                                  self.feature_model, self.feature_names, self.scalar, self.clf_lin,\n",
        "                                  self.list_index, self.selection_model)\n",
        "        spam_cnt = spam_cnt+spam_cnt_1\n",
        "        time.sleep(0.1)\n",
        "        print(\"Exiting \" + self.name)\n",
        "\n",
        "\n",
        "\n",
        "def m2_empty_out(name, spam_message, identified_magic_words, method, feature_model, feature_names, scalar, clf_lin, list_index, selection_model):\n",
        "    m2_empty_1 = pd.DataFrame()\n",
        "    spam_cnt_1 = 0\n",
        "    global m2_list\n",
        "\n",
        "    for j in spam_message.message:\n",
        "        choose_email = [j + identified_magic_words]\n",
        "        message_14_email = pd.DataFrame(choose_email, columns=[\"message\"])\n",
        "        message_14_tf_idf = single_transform(\n",
        "            message_14_email[\"message\"], method, feature_model, feature_names, scalar, selection_model)\n",
        "        message_14_tf_idf = pd.DataFrame(\n",
        "            message_14_tf_idf.toarray(), columns=feature_names)\n",
        "        message_14_y = [1]\n",
        "        message_14_y = pd.Series(message_14_y)\n",
        "        message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
        "        message_14_pred = clf_lin.predict(message_CData.X)\n",
        "\n",
        "        if message_14_pred == 0:\n",
        "            spam_cnt_1 += 1\n",
        "            m2_empty_1 = pd.concat([m2_empty_1, message_14_tf_idf], ignore_index=True)\n",
        "\n",
        "    m2_list[list_index] = pd.concat([m2_list[list_index], m2_empty_1], ignore_index=True)\n",
        "\n",
        "    return spam_cnt_1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def svm_attack(method, clf_lin, spam, identified_magic_words, feature_model, feature_names, scalar, selection_model):\n",
        "\n",
        "    global m2_empty\n",
        "\n",
        "    spam_messages = np.array_split(spam, 4)\n",
        "\n",
        "    print(\"Start processing message\")\n",
        "\n",
        "    thread1 = myThread(1, \"Thread-1\", spam_messages[0], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 0, selection_model)\n",
        "    thread2 = myThread(2, \"Thread-2\", spam_messages[1], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 1, selection_model)\n",
        "    thread3 = myThread(3, \"Thread-3\", spam_messages[2], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 2, selection_model)\n",
        "    thread4 = myThread(4, \"Thread-4\", spam_messages[3], identified_magic_words,\n",
        "                       method, feature_model, feature_names, scalar, clf_lin, 3, selection_model)\n",
        "\n",
        "    threads.append(thread1)\n",
        "    threads.append(thread2)\n",
        "    threads.append(thread3)\n",
        "    threads.append(thread4)\n",
        "\n",
        "    for t in threads:\n",
        "        t.start()\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    m2_empty = pd.concat(m2_list, ignore_index=True)\n",
        "\n",
        "    print(\"Exiting Main Thread\")\n",
        "    print('White box attack on SVM:')\n",
        "    print('Number of samples provided:', len(spam))\n",
        "    print('Number of crafted sample that got misclassified:', spam_cnt)\n",
        "    print('Successful rate:', spam_cnt / len(spam))\n",
        "\n",
        "    return m2_empty\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raxGc9-UsT6d"
      },
      "source": [
        "**Run the code block below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo5YVW5zw0Iu",
        "outputId": "8151fba8-10df-4f88-91a1-a7e779b8e107"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start processing message\n",
            "Starting Thread-1\n",
            "Starting Thread-2Starting Thread-3\n",
            "Starting Thread-4\n",
            "\n",
            "Exiting Thread-1\n",
            "Exiting Thread-3\n",
            "Exiting Thread-2\n",
            "Exiting Thread-4\n",
            "Exiting Main Thread\n",
            "White box attack on SVM:\n",
            "Number of samples provided: 77\n",
            "Number of crafted sample that got misclassified: 45\n",
            "Successful rate: 0.5844155844155844\n"
          ]
        }
      ],
      "source": [
        "m2_empty = svm_attack('TFIDF', clf_lin, spam_test, identified_magic_words, feature_model, feature_names, scalar, 'NaN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQOQYRvy4QBG"
      },
      "source": [
        "### **Question 6**\n",
        "Is the successful rate shown above higher or lower than the false negative rate of the classifer? Does that mean our attack is effective?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX--S66z4SF8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znZP1evnzPPd"
      },
      "source": [
        "### **Task 4**\n",
        "Now we will try to craft individual emails by manually changing the text.\n",
        "Follow the steps below for 5 emails: \\\\\n",
        "\n",
        "1. Choose an email from the spam dataset.\n",
        "2. Copy the selected email into the code block.\n",
        "3. Add a single magical word obtained from the results of Section 6 to the email, placing it where you see fit.\n",
        "4. Run the code to check if the label is flipped from spam (1) to non-spam (0).\n",
        "5. If the label is flipped, stop. If not, repeat steps 3 and 4 (*add additional magic word*) until the label is flipped or until you've run out of magical words.\n",
        "\n",
        "Tips:\n",
        "1. Here you should note, what exactly is \"Spam Emails\" in this case.\n",
        "2. What should the magical words added to spam_emails be generated from? Is it our validation data or test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XTYSvT12j5y",
        "outputId": "7837b4fb-3e0e-489d-898d-351f2c79d990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                message  label\n",
            "1846  virtual girlfriend virtual boyfriend artificia...      1\n",
            "1501  warning great interested visit web site http c...      1\n",
            "965   list owner kiddin invited join mailing list li...      1\n",
            "1027  dear friend responded following announcement d...      1\n",
            "1594  sexxx site approved clinton click click remove...      1\n",
            "...                                                 ...    ...\n",
            "1411  b r g n r f r e s stop travel supplier air hot...      1\n",
            "2144  dear internet user dear internet user sound fa...      1\n",
            "347   k st mo income home based business booming mlm...      1\n",
            "80    innovative publically traded company offer par...      1\n",
            "1068  earn month home based business legally pay lit...      1\n",
            "\n",
            "[77 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# All Spam Emails\n",
        "print(spam_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fqlpi6q3P4-",
        "outputId": "fadb0e9f-2793-41ff-c2d1-5eaac35b2de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "virtual girlfriend virtual boyfriend artificial intelligence program ibm pc compatible macintosh watch talk ask question tell secret relate watch ask different clothes guide different activity watch participate hottest sexual activity available computer including sexual position using unique toy bringing multiple partner doubt realistic sexually stimulating computer game available remember birthday like dislike time start program say different thing act differently time different personality vga digital graphic virtual girlfriend virtual boyfriend software hottest sexiest graphic soundblaster compatible card actually hear voice talk adult software title designed heterosexual homosexual people like try actual copy market sold actual price information people think program try write comment thank interested like order copy read mailing instruction come unmarked package sent day order received mailing list whatsoever guaranteed run higher ibm compatibles required vga graphic hard drive sound card optional macintosh requires meg ram virtual girlfriend virtual boyfriend artificial intelligence program meaning completely interactive just like talking actually simple conversation attitude change different thing say say thing upset say thing play talk learn like really blast movie coming virtual reality s amazing actually virtual reality program like computer s easy install instruction easy follow special software offer inform new adult game vcs magazine rated best game search paradise doubt greatest xxx adult game available game fun turn travel world continent country think meet beautiful woman existence woman treat like king obey command sexual wish think woman know different paradise guy game game real model digital video digital sound make realistic possible feel like room girl talking added bonus ll receive club celebrity x meet talk way celebrity choice imagine club beautiful known actual celebrity seen girl t v magazine billboard ad computer begging action game hot start playing wont able stop required better meg ram better window higher win fine sound card optional rom optional game given cd rom compressed diskette order just request program come password protection utility allows program run correct password entered purchase following form mail address feel free write order form hand send mark wrhel p o box tujunga ca date address city state zip code phone e mail address ibm mac cd rom disk virtual girdfriend boyfriend just search paradise club celebrity x search paradise club celebrity x virtual girlfriend virtual boyfriend just\n"
          ]
        }
      ],
      "source": [
        "# Choose by varying numbers\n",
        "print(spam_test.message.values[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qygv01a_zOGe",
        "outputId": "043d90c4-f0fe-418f-bf09-0e5f7b753a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the label after injecting magical word: CArray([0])\n"
          ]
        }
      ],
      "source": [
        "choose_email = ['The email content you chose + magical word']\n",
        "message_14_email = pd.DataFrame(choose_email, columns=[\"message\"])\n",
        "message_14_tf_idf = single_transform(message_14_email[\"message\"], 'TFIDF',\n",
        "                    feature_model, feature_names, scalar,\n",
        "                    'NaN')\n",
        "message_14_tf_idf = pd.DataFrame(message_14_tf_idf.toarray(), columns=feature_names)\n",
        "message_14_y = [1]\n",
        "message_14_y = pd.Series(message_14_y)\n",
        "message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
        "message_14_pred = clf_lin.predict(message_CData.X)\n",
        "\n",
        "# if the output is something like CArray([0]), then you flipped the label\n",
        "print('the label after injecting magical word:', message_14_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqgxp_kT4KgP"
      },
      "source": [
        "### **Question 7**\n",
        "How many emails successfully went through (classifiction label flipped to 0) after adding magical words? For each of these emails, how many magical words did you add? (Choose at least 5 emails)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrzWj7MU5Lwu"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
